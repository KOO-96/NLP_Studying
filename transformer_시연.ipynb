{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1zxeB9gCpIp8YBadPZMKwG6eOj84yF8Me",
      "authorship_tag": "ABX9TyN/leaStTyjpZNKlcCPrzS5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KOO-96/NLP_Studying/blob/main/transformer_%EC%8B%9C%EC%97%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JvMVTLokMed"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# xls_a = pd.read_excel('/content/drive/MyDrive/트랜스포머/data/data1.xlsx', index_col=None)\n",
        "# xls_b = pd.read_excel('/content/drive/MyDrive/트랜스포머/data/data2.xlsx', index_col=None)\n",
        "\n",
        "# xls_a.to_csv('/content/drive/MyDrive/트랜스포머/data/data1.csv', encoding='utf-8', index=False)\n",
        "# xls_b.to_csv('/content/drive/MyDrive/트랜스포머/data/data2.csv', encoding='utf-8', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/drive/MyDrive/트랜스포머/data/data1.csv', encoding = 'utf-8', index_col=0)\n",
        "data = data[:30000]\n",
        "# data2 = pd.read_csv('/content/drive/MyDrive/트랜스포머/data/data2.csv', encoding = 'utf-8')"
      ],
      "metadata": {
        "id": "CUsGsROqmTP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "xA1NxWjvmnoj",
        "outputId": "bec88100-6067-46dd-cf3c-b9de03a208d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                      원문  \\\n",
              "SID                                                        \n",
              "1      'Bible Coloring'은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 ...   \n",
              "2                                           씨티은행에서 일하세요?   \n",
              "3                  푸리토의 베스트셀러는 해외에서 입소문만으로 4차 완판을 기록하였다.   \n",
              "4       11장에서는 예수님이 이번엔 나사로를 무덤에서 불러내어 죽은 자 가운데서 살리셨습니다.   \n",
              "5         6.5, 7, 8 사이즈가 몇 개나 더 재입고 될지 제게 알려주시면 감사하겠습니다.   \n",
              "...                                                  ...   \n",
              "29996                             그는 충격받았는지 아무 표정이 없습니다.   \n",
              "29997                      그는 충분히 비난받았고, 이제 내가 비난받을 차례야.   \n",
              "29998                        그는 충청북도 청주시 상당구 서문동에 살고 있다.   \n",
              "29999                                   그는 취미가 아무것도 없어요?   \n",
              "30000                            그는 치료를 위해 병원으로 후송되었습니다.   \n",
              "\n",
              "                                                     번역문  \n",
              "SID                                                       \n",
              "1      Bible Coloring' is a coloring application that...  \n",
              "2                            Do you work at a City bank?  \n",
              "3      PURITO's bestseller, which recorded 4th rough ...  \n",
              "4      In Chapter 11 Jesus called Lazarus from the to...  \n",
              "5      I would feel grateful to know how many stocks ...  \n",
              "...                                                  ...  \n",
              "29996  He looks shocked and doesn't have any facial e...  \n",
              "29997   He was thoroughly criticized and now is my turn.  \n",
              "29998  He is living in Seomun-dong, Sangdang-gu, Cheo...  \n",
              "29999                       Doesn't he have any hobbies?  \n",
              "30000      He was carried to the hospital for treatment.  \n",
              "\n",
              "[30000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb321a4c-cbf6-47da-a543-8b3f4bdc24dc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>원문</th>\n",
              "      <th>번역문</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'Bible Coloring'은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 ...</td>\n",
              "      <td>Bible Coloring' is a coloring application that...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>씨티은행에서 일하세요?</td>\n",
              "      <td>Do you work at a City bank?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>푸리토의 베스트셀러는 해외에서 입소문만으로 4차 완판을 기록하였다.</td>\n",
              "      <td>PURITO's bestseller, which recorded 4th rough ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11장에서는 예수님이 이번엔 나사로를 무덤에서 불러내어 죽은 자 가운데서 살리셨습니다.</td>\n",
              "      <td>In Chapter 11 Jesus called Lazarus from the to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6.5, 7, 8 사이즈가 몇 개나 더 재입고 될지 제게 알려주시면 감사하겠습니다.</td>\n",
              "      <td>I would feel grateful to know how many stocks ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>그는 충격받았는지 아무 표정이 없습니다.</td>\n",
              "      <td>He looks shocked and doesn't have any facial e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>그는 충분히 비난받았고, 이제 내가 비난받을 차례야.</td>\n",
              "      <td>He was thoroughly criticized and now is my turn.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>그는 충청북도 청주시 상당구 서문동에 살고 있다.</td>\n",
              "      <td>He is living in Seomun-dong, Sangdang-gu, Cheo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>그는 취미가 아무것도 없어요?</td>\n",
              "      <td>Doesn't he have any hobbies?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30000</th>\n",
              "      <td>그는 치료를 위해 병원으로 후송되었습니다.</td>\n",
              "      <td>He was carried to the hospital for treatment.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb321a4c-cbf6-47da-a543-8b3f4bdc24dc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bb321a4c-cbf6-47da-a543-8b3f4bdc24dc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bb321a4c-cbf6-47da-a543-8b3f4bdc24dc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aa93e6fe-b94f-4918-aaaf-f7f6dd872916\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aa93e6fe-b94f-4918-aaaf-f7f6dd872916')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aa93e6fe-b94f-4918-aaaf-f7f6dd872916 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_bfcaae9d-1573-4946-a09c-0b7c57a1528f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bfcaae9d-1573-4946-a09c-0b7c57a1528f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 30000,\n  \"fields\": [\n    {\n      \"column\": \"SID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8660,\n        \"min\": 1,\n        \"max\": 30000,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          2309,\n          22405,\n          23398\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc6d0\\ubb38\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          \"1954\\ub144 5\\uc6d4 31\\uc77c \\uad00\\ub3c8 \\ub300\\ud559\\uad50\\uac00 \\ubc1c\\uacac\\ub418\\uc5b4 \\uce74\\ud1a8\\ub9ad \\uc7ac\\ub2e8\\uc744 \\uc778\\uc218\\ud558\\uace0 \\ud604\\uc7ac \\uce74\\ud1a8\\ub9ad \\uad00\\ub3c8 \\ub300\\ud559\\uad50\\ub85c \\uc7ac\\uac1c\\uc7a5\\ud558\\uc600\\uc2b5\\ub2c8\\ub2e4.\",\n          \"\\uadf8\\uac8c \\uadfc\\ucc98\\uc5d0 \\ub5a8\\uc5b4\\uc838 \\uc788\\uc9c4 \\uc54a\\uc740\\uc9c0 \\ud655\\uc778\\ud574 \\ubcf4\\uc168\\ub098\\uc694?\",\n          \"\\uadf8\\ub140\\uac00 \\ub3c4\\uc6c0\\uc774 \\ud544\\uc694\\ud588\\uae30\\ub54c \\ubb38\\uc5d0 \\uc81c\\uac00 \\ub3c4\\uc640\\uc900 \\uac70\\uc5d0\\uc694.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ubc88\\uc5ed\\ubb38\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          \"Kwandon Univesity was found May 31st, 1954 and took over Catholic Foundation and now reopened as Catholic Kwandon Univesity.\",\n          \"Have you checked whether if it's there?\",\n          \"She needed help, so I helped her.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# kor / eng split\n",
        "\n",
        "kor_text = []\n",
        "eng_text = []\n",
        "\n",
        "for _, row in data.iterrows():\n",
        "  kor, eng = row\n",
        "  kor_text.append(kor)\n",
        "  eng_text.append(eng)"
      ],
      "metadata": {
        "id": "hMWjKpoVlprZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for kor, eng in zip(kor_text[:5], eng_text[:5]):\n",
        "  print(f\"[KOR] : {kor}\")\n",
        "  print(f\"[ENG] : {eng}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b2wgZisl-jz",
        "outputId": "a0ebec82-e19d-458a-e4c3-aa30fff68b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[KOR] : 'Bible Coloring'은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 앱입니다.\n",
            "[ENG] : Bible Coloring' is a coloring application that allows you to experience beautiful stories in the Bible.\n",
            "[KOR] : 씨티은행에서 일하세요?\n",
            "[ENG] : Do you work at a City bank?\n",
            "[KOR] : 푸리토의 베스트셀러는 해외에서 입소문만으로 4차 완판을 기록하였다.\n",
            "[ENG] : PURITO's bestseller, which recorded 4th rough -cuts by words of mouth from abroad.\n",
            "[KOR] : 11장에서는 예수님이 이번엔 나사로를 무덤에서 불러내어 죽은 자 가운데서 살리셨습니다.\n",
            "[ENG] : In Chapter 11 Jesus called Lazarus from the tomb and raised him from the dead.\n",
            "[KOR] : 6.5, 7, 8 사이즈가 몇 개나 더 재입고 될지 제게 알려주시면 감사하겠습니다.\n",
            "[ENG] : I would feel grateful to know how many stocks will be secured of size 6.5, 7, and 8.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# kor torkenizer txt생성\n",
        "with open('kor_train.txt', 'w', encoding = 'utf-8') as f:\n",
        "  for line in kor_text:\n",
        "    print(line, file = f)\n",
        "\n",
        "# eng torkenizer txt생성\n",
        "with open('eng_train.txt', 'w', encoding = 'utf-8') as f:\n",
        "  for line in eng_text:\n",
        "    print(line, file = f)"
      ],
      "metadata": {
        "id": "9sT4ARAFmQT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer parameter\n",
        "params = {\n",
        "    'batch_size': 64,\n",
        "    'num_epoch': 5,\n",
        "    'dropout': 0.1,\n",
        "    'min_frequency': 2,\n",
        "    'vocab_size': 10000,\n",
        "    'num_layers': 6,\n",
        "    'num_heads': 8,\n",
        "    'hidden_dim': 512,\n",
        "    'ffn_dim': 2048,\n",
        "}"
      ],
      "metadata": {
        "id": "aKBOIINum7bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, decoders\n",
        "\n",
        "tokenizer_model = models.BPE()\n",
        "kor_tokenizer = Tokenizer(tokenizer_model)\n",
        "\n",
        "trainer = trainers.BpeTrainer(\n",
        "    vocab_size = params['vocab_size'],\n",
        "    min_frequency = params['min_frequency'],\n",
        "    special_tokens = ['[PAD]', '[SOS]', '[EOS]', '[UNK]'],\n",
        "    suffix = ''\n",
        ")\n",
        "\n",
        "kor_tokenizer.train(files = ['kor_train.txt'], trainer = trainer)"
      ],
      "metadata": {
        "id": "nAmp4j7HyVnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, decoders\n",
        "\n",
        "tokenizer_model = models.BPE()\n",
        "eng_tokenizer = Tokenizer(tokenizer_model)\n",
        "\n",
        "trainer = trainers.BpeTrainer(\n",
        "    vocab_size = params['vocab_size'],\n",
        "    min_frequency = params['min_frequency'],\n",
        "    special_tokens = ['[PAD]', '[SOS]', '[EOS]', '[UNK]'],\n",
        "    suffix = ''\n",
        ")\n",
        "\n",
        "eng_tokenizer.train(files = ['eng_train.txt'], trainer = trainer)"
      ],
      "metadata": {
        "id": "jqRpq4PZzlGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad_idx = kor_tokenizer.token_to_id('[PAD]')\n",
        "sos_idx = kor_tokenizer.token_to_id('[SOS]')\n",
        "eos_idx = kor_tokenizer.token_to_id('[EOS]')"
      ],
      "metadata": {
        "id": "3SRXNnTFnitj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kor_encoded_data = kor_tokenizer.encode_batch(kor_text)\n",
        "eng_encoded_data = eng_tokenizer.encode_batch(eng_text)"
      ],
      "metadata": {
        "id": "0NaqKOvuni3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for origin, processed in zip(kor_text[:3], kor_encoded_data[:3]):\n",
        "  print(f\"[ORIGIN] : {origin}\")\n",
        "  print(f\"[PROCESSED] : {processed.tokens}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcapKtqx2me6",
        "outputId": "eef5c3c4-fda0-4a85-8a81-e0f53108e851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ORIGIN] : 'Bible Coloring'은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 앱입니다.\n",
            "[PROCESSED] : [\"'\", 'B', 'ib', 'le ', 'C', 'ol', 'or', 'ing', \"'은 \", '성', '경', '의 ', '아름다', '운', ' 이야기를 ', '체험', ' ', '할 수 있는 ', '컬러', '링 ', '앱', '입니다', '.']\n",
            "\n",
            "[ORIGIN] : 씨티은행에서 일하세요?\n",
            "[PROCESSED] : ['씨', '티', '은행', '에서 일', '하', '세', '요?']\n",
            "\n",
            "[ORIGIN] : 푸리토의 베스트셀러는 해외에서 입소문만으로 4차 완판을 기록하였다.\n",
            "[PROCESSED] : ['푸', '리', '토', '의 ', '베', '스트', '셀러', '는 ', '해외에서 ', '입', '소문', '만으로 ', '4차 ', '완', '판', '을 기', '록', '하였', '다', '.']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for origin, processed in zip(eng_text[:3], eng_encoded_data[:3]):\n",
        "  print(f\"[ORIGIN] : {origin}\")\n",
        "  print(f\"[PROCESSED] : {processed.tokens}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LGIYLsF2vMi",
        "outputId": "a75bf2ed-ce8d-48a7-87c6-82808dc49ee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ORIGIN] : Bible Coloring' is a coloring application that allows you to experience beautiful stories in the Bible.\n",
            "[PROCESSED] : ['B', 'ible ', 'Col', 'or', 'ing', \"' \", 'is a ', 'color', 'ing ', 'applic', 'ation that ', 'allows ', 'you to ', 'experience ', 'beautiful ', 'stories ', 'in the ', 'B', 'i', 'ble', '.']\n",
            "\n",
            "[ORIGIN] : Do you work at a City bank?\n",
            "[PROCESSED] : ['Do ', 'you w', 'ork ', 'at a ', 'City ', 'bank', '?']\n",
            "\n",
            "[ORIGIN] : PURITO's bestseller, which recorded 4th rough -cuts by words of mouth from abroad.\n",
            "[PROCESSED] : ['P', 'UR', 'IT', 'O', \"'s \", 'best', 'sell', 'er, ', 'which ', 'record', 'ed ', '4th ', 'rough ', '-', 'cut', 's by ', 'word', 's of ', 'mouth ', 'from ', 'ab', 'road', '.']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CTSciVtC4GuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 후처리\n",
        "\n",
        "kor_len_max = max(len(line.tokens) for line in kor_encoded_data)\n",
        "eng_len_max = max(len(line.tokens) for line in eng_encoded_data)\n",
        "kor_len, eng_len = 0, 0\n",
        "\n",
        "for line in kor_encoded_data:\n",
        "  kor_len += len(line.tokens)\n",
        "kor_len_avg = kor_len / len(kor_encoded_data)\n",
        "\n",
        "print(kor_len_avg, kor_len_max)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLNvX96K4HNd",
        "outputId": "d374b8b5-971a-491b-ed79-7a563d5f9831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13.249866666666666 51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for line in eng_encoded_data:\n",
        "  eng_len += len(line.tokens)\n",
        "eng_len_avg = eng_len / len(eng_encoded_data)\n",
        "\n",
        "print(eng_len_avg, eng_len_max)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOZUJfkU4HUe",
        "outputId": "b1943086-4140-4894-dc01-7249e957291c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12.646066666666666 59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params['max_len'] = 60"
      ],
      "metadata": {
        "id": "yglnocDw4HZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sentence(input_ids):\n",
        "  num_pad = params['max_len'] - len(input_ids)\n",
        "  input_ids.extend([pad_idx] * num_pad)\n",
        "  return input_ids"
      ],
      "metadata": {
        "id": "ZtPT1lHC4Hes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess(input_ids):\n",
        "    '''입력 문장에 [SOS] 토큰과 [EOS] 토큰 부여'''\n",
        "\n",
        "    input_ids = pad_sentence(input_ids)\n",
        "\n",
        "    input_ids = [sos_idx] + input_ids\n",
        "\n",
        "    input_ids = input_ids[:params['max_len']]\n",
        "\n",
        "    if pad_idx in input_ids:\n",
        "        pad_start = input_ids.index(pad_idx)\n",
        "        input_ids[pad_start] = eos_idx\n",
        "    else:\n",
        "        input_ids[-1] = eos_idx\n",
        "\n",
        "    return input_ids"
      ],
      "metadata": {
        "id": "OwCmGHME4His"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent = '우리 진짜 별나대 그냥 내가 너무 좋아해 넌 그걸 너무 잘 알고 날 쥐락펴락해 나도 마찬가지인걸'\n",
        "\n",
        "proc_sent = kor_tokenizer.encode(sent)\n",
        "print(f'토큰화 결과: {proc_sent.tokens}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnAUU5U44HmZ",
        "outputId": "de9af2ed-7b94-40cb-b6fb-4f4aee608911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "토큰화 결과: ['우리 ', '진짜 ', '별', '나', '대 ', '그냥 내가 ', '너무 ', '좋아', '해 ', '넌', ' 그', '걸 ', '너무 ', '잘 ', '알고 ', '날 ', '쥐', '락', '펴', '락', '해 ', '나도 ', '마찬', '가지', '인', '걸']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "post_proc_sent = postprocess(proc_sent.ids)\n",
        "\n",
        "print(f'후처리 결과: {post_proc_sent}\\n')\n",
        "print(f'후처리 해석: {kor_tokenizer.decode(post_proc_sent)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHRyxRWW4Hpr",
        "outputId": "82162992-19a7-4ffe-8dee-cd1e9581c3d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "후처리 결과: [1, 1900, 5182, 734, 293, 1932, 7503, 1774, 1697, 1596, 323, 2140, 2040, 1774, 1689, 5453, 1980, 1152, 529, 2]\n",
            "\n",
            "후처리 해석: 우리  진짜  별 나 대  그냥 내가  너무  좋아 해  넌  그 걸  너무  잘  알고  날  쥐 락\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kor_processed_data = [postprocess(data.ids) for data in kor_encoded_data]\n",
        "eng_processed_data = [postprocess(data.ids) for data in eng_encoded_data]"
      ],
      "metadata": {
        "id": "DTMQ61OO4Hs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "kor_tensors = [torch.LongTensor(line).to(device) for line in kor_processed_data]\n",
        "eng_tensors = [torch.LongTensor(line).to(device) for line in eng_processed_data]\n",
        "\n",
        "src_iter = DataLoader(kor_tensors, batch_size=params['batch_size'])\n",
        "tgt_iter = DataLoader(eng_tensors, batch_size=params['batch_size'])"
      ],
      "metadata": {
        "id": "3k9QyXie76KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.manual_seed(32)\n",
        "torch.cuda.manual_seed(32)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "zp85IafI76PP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    '''멀티 헤드 어텐션 레이어'''\n",
        "    def __init__(self, params):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert params['hidden_dim'] % params['num_heads'] == 0,\n",
        "        self.num_heads = params['num_heads']\n",
        "        self.attn_dim = params['hidden_dim'] // self.num_heads\n",
        "\n",
        "        self.q_w = nn.Linear(params['hidden_dim'], self.num_heads * self.attn_dim)\n",
        "        self.k_w = nn.Linear(params['hidden_dim'], self.num_heads * self.attn_dim)\n",
        "        self.v_w = nn.Linear(params['hidden_dim'], self.num_heads * self.attn_dim)\n",
        "\n",
        "        self.o_w = nn.Linear(self.num_heads * self.attn_dim, params['hidden_dim'])\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        \" q, k, v = [배치 사이즈, 문장 길이, 은닉 차원] \"\n",
        "\n",
        "        batch_size = q.size(0)\n",
        "\n",
        "        q = self.q_w(q).view(batch_size, -1, self.num_heads, self.attn_dim).transpose(1, 2)\n",
        "        k = self.k_w(k).view(batch_size, -1, self.num_heads, self.attn_dim).transpose(1, 2)\n",
        "        v = self.v_w(v).view(batch_size, -1, self.num_heads, self.attn_dim).transpose(1, 2)\n",
        "        # q, k, v = [배치 사이즈, 헤드 갯수, 문장 길이, 어텐션 차원]\n",
        "\n",
        "        attn = torch.matmul(q, k.transpose(-1, -2))\n",
        "        # attn = [배치 사이즈, 헤드 갯수, 문장 길이, 문장 길이]\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = mask.unsqueeze(1)\n",
        "            attn.masked_fill(mask==0, -1e9)\n",
        "\n",
        "        score = F.softmax(attn, dim=-1)\n",
        "        # score = [배치 사이즈, 헤드 갯수, 문장 길이, 문장 길이]\n",
        "\n",
        "        output = torch.matmul(score, v)\n",
        "        # output = [배치 사이즈, 헤드 갯수, 문장 길이, 어텐션 차원]\n",
        "\n",
        "        output = output.transpose(1, 2).contiguous()\n",
        "        # output = [배치 사이즈, 문장 길이, 헤드 갯수, 어텐션 차원]\n",
        "\n",
        "        output = output.view(batch_size, -1, self.num_heads * self.attn_dim)\n",
        "        # output = [배치 사이즈, 문장 길이, 은닉 차원]\n",
        "\n",
        "        output = self.o_w(output)\n",
        "        # output = [배치 사이즈, 문장 길이, 은닉 차원]\n",
        "\n",
        "        return output, score"
      ],
      "metadata": {
        "id": "_ZHhcDHO76Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_subsequent_mask(tgt):\n",
        "    batch_size, tgt_len = tgt.size()\n",
        "\n",
        "    subsequent_mask = torch.triu(torch.ones(tgt_len, tgt_len), diagonal=1).bool()\n",
        "    # subsequent_mask = [타겟 문장 길이, 타겟 문장 길이]\n",
        "\n",
        "    subsequent_mask = subsequent_mask.unsqueeze(0).repeat(batch_size, 1, 1).to(device)\n",
        "    # subsquent_mask = [배치 사이즈, 타겟 문장 길이, 타겟 문장 길이]\n",
        "\n",
        "    return subsequent_mask"
      ],
      "metadata": {
        "id": "0rDcB2k_76YG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sent = '평온했던 하늘이 무너지고,'\n",
        "test_tensor = kor_tokenizer.encode(test_sent)\n",
        "test_tensor = torch.LongTensor(test_tensor.ids).to(device).unsqueeze(0)\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.imshow(create_subsequent_mask(test_tensor).cpu()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "Ba1BzSmp76cp",
        "outputId": "bb4f5e3b-0b2d-4e19-db29-09820370fb84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7d93e086dae0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_src_mask(src):\n",
        "    \" source = [배치 사이즈, 소스 문장 길이] \"\n",
        "\n",
        "    src_len = src.size(1)\n",
        "\n",
        "    src_mask = (src == pad_idx)\n",
        "    # src_mask = [배치 사이즈, 소스 문장 길이]\n",
        "\n",
        "    src_mask = src_mask.unsqueeze(1).repeat(1, src_len, 1)\n",
        "    # src_mask = [배치 사이즈, 소스 문장 길이, 소스 문장 길이]\n",
        "\n",
        "    return src_mask.to(device)\n",
        "\n",
        "\n",
        "def create_tgt_mask(src, tgt):\n",
        "    \" src = [배치 사이즈, 소스 문장 길이] \"\n",
        "    \" tgt = [배치 사이즈, 타겟 문장 길이] \"\n",
        "\n",
        "    batch_size, tgt_len = tgt.size()\n",
        "\n",
        "    subsequent_mask = create_subsequent_mask(tgt)\n",
        "\n",
        "    enc_dec_mask = (src == pad_idx)\n",
        "    tgt_mask = (tgt == pad_idx)\n",
        "    # src_mask = [배치 사이즈, 소스 문장 길이]\n",
        "    # tgt_mask = [배치 사이즈, 타겟 문장 길이]\n",
        "\n",
        "    enc_dec_mask = enc_dec_mask.unsqueeze(1).repeat(1, tgt_len, 1).to(device)\n",
        "    tgt_mask = tgt_mask.unsqueeze(1).repeat(1, tgt_len, 1).to(device)\n",
        "    # src_mask = [배치 사이즈, 타겟 문장 길이, 소스 문장 길이]\n",
        "    # tgt_mask = [배치 사이즈, 타겟 문장 길이, 타겟 문장 길이]\n",
        "\n",
        "    tgt_mask = tgt_mask | subsequent_mask\n",
        "\n",
        "    return enc_dec_mask, tgt_mask"
      ],
      "metadata": {
        "id": "eVeXPNm776rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 5-2. Position-wise Feed-Forward 네트워크 구현\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    '''포지션 와이즈 피드 포워드 레이어'''\n",
        "    def __init__(self, parmas):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.fc1 = nn.Linear(params['hidden_dim'], params['ffn_dim'])\n",
        "        self.fc2 = nn.Linear(params['ffn_dim'], params['hidden_dim'])\n",
        "        self.dropout = nn.Dropout(params['dropout'])\n",
        "\n",
        "    def forward(self, x):\n",
        "        \" x = [배치 사이즈, 문장 길이, 은닉 차원] \"\n",
        "\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "JeCmgjn28MnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        sinusoid = np.array([pos / np.power(10000, 2 * i / params['hidden_dim'])\n",
        "                            for pos in range(params['max_len']) for i in range(params['hidden_dim'])])\n",
        "        # sinusoid = [문장 최대 길이 * 은닉 차원]\n",
        "\n",
        "        sinusoid = sinusoid.reshape(params['max_len'], -1)\n",
        "        # sinusoid = [문장 최대 길이, 은닉 차원]\n",
        "\n",
        "        sinusoid[:, 0::2] = np.sin(sinusoid[:, 0::2])\n",
        "        sinusoid[:, 1::2] = np.cos(sinusoid[:, 1::2])\n",
        "        sinusoid = torch.FloatTensor(sinusoid).to(device)\n",
        "\n",
        "        self.embedding = nn.Embedding.from_pretrained(sinusoid, freeze=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \" x = [배치 사이즈, 문장 길이] \"\n",
        "\n",
        "        pos = torch.arange(x.size(-1), dtype=torch.long).to(device)\n",
        "        # pos = [배치 사이즈, 문장 길이]\n",
        "\n",
        "        embed = self.embedding(pos)\n",
        "        # embed = [배치 사이즈, 문장 길이, 은닉 차원]\n",
        "        return embed"
      ],
      "metadata": {
        "id": "VLitrz7w_uBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    '''인코더 레이어'''\n",
        "    def __init__(self, params):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(params)\n",
        "        self.layer_norm1 = nn.LayerNorm(params['hidden_dim'])\n",
        "        self.feed_forward = PositionwiseFeedForward(params)\n",
        "        self.layer_norm2 = nn.LayerNorm(params['hidden_dim'])\n",
        "        self.dropout = nn.Dropout(params['dropout'])\n",
        "\n",
        "    def forward(self, x, src_mask):\n",
        "        \" x = [배치 사이즈, 문장 길이, 은닉 차원] \"\n",
        "\n",
        "        residual = x\n",
        "        x, _ = self.self_attn(x, x, x, src_mask)\n",
        "        x = self.dropout(x)\n",
        "        x = residual + x\n",
        "        x = self.layer_norm1(x)\n",
        "\n",
        "        residual = x\n",
        "        x = self.feed_forward(x)\n",
        "        x = self.dropout(x)\n",
        "        x = residual + x\n",
        "        x = self.layer_norm2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.tok_embedding = nn.Embedding(params['vocab_size'], params['hidden_dim'], padding_idx=pad_idx)\n",
        "        self.pos_embedding = PositionalEncoding(params)\n",
        "        self.layers = nn.ModuleList([EncoderLayer(params) for _ in range(params['num_layers'])])\n",
        "\n",
        "    def forward(self, src):\n",
        "        \" src = [배치 사이즈, 소스 문장 길이] \"\n",
        "\n",
        "        src_mask = create_src_mask(src)\n",
        "        src = self.tok_embedding(src) + self.pos_embedding(src)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "\n",
        "        # src = [배치 사이즈, 소스 문장 길이, 은닉 차원]\n",
        "        return src"
      ],
      "metadata": {
        "id": "Nrcm8k_48M2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    '''디코더 레이어'''\n",
        "    def __init__(self, params):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(params)\n",
        "        self.layer_norm1 = nn.LayerNorm(params['hidden_dim'])\n",
        "\n",
        "        self.enc_dec_attn = MultiHeadAttention(params)\n",
        "        self.layer_norm2 = nn.LayerNorm(params['hidden_dim'])\n",
        "\n",
        "        self.feed_forward = PositionwiseFeedForward(params)\n",
        "        self.layer_norm3 = nn.LayerNorm(params['hidden_dim'])\n",
        "\n",
        "        self.dropout = nn.Dropout(params['dropout'])\n",
        "\n",
        "    def forward(self, x, tgt_mask, enc_output, src_mask):\n",
        "        \" x = [배치 사이즈, 문장 길이, 은닉 차원] \"\n",
        "\n",
        "        residual = x\n",
        "        x, _ = self.self_attn(x, x, x, tgt_mask)\n",
        "        x = self.dropout(x)\n",
        "        x = residual + x\n",
        "        x = self.layer_norm1(x)\n",
        "\n",
        "        residual = x\n",
        "        x, attn_map = self.enc_dec_attn(x, enc_output, enc_output, src_mask)\n",
        "        x = self.dropout(x)\n",
        "        x = residual + x\n",
        "        x = self.layer_norm2(x)\n",
        "\n",
        "        residual = x\n",
        "        x = self.feed_forward(x)\n",
        "        x = self.dropout(x)\n",
        "        x = residual + x\n",
        "        x = self.layer_norm3(x)\n",
        "\n",
        "        return x, attn_map\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.tok_embedding = nn.Embedding(params['vocab_size'], params['hidden_dim'], padding_idx=pad_idx)\n",
        "        self.pos_embedding = PositionalEncoding(params)\n",
        "        self.layers = nn.ModuleList([DecoderLayer(params) for _ in range(params['num_layers'])])\n",
        "\n",
        "    def forward(self, tgt, src, enc_out):\n",
        "        \" tgt = [배치 사이즈, 타겟 문장 길이] \"\n",
        "\n",
        "        src_mask, tgt_mask = create_tgt_mask(src, tgt)\n",
        "        tgt = self.tok_embedding(tgt) + self.pos_embedding(tgt)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            tgt, attn_map = layer(tgt, tgt_mask, enc_out, src_mask)\n",
        "\n",
        "        tgt = torch.matmul(tgt, self.tok_embedding.weight.transpose(0, 1))\n",
        "        # tgt = [배치 사이즈, 타겟 문장 길이, 은닉 차원]\n",
        "\n",
        "        return tgt, attn_map"
      ],
      "metadata": {
        "id": "pVnBSWHL8M-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    '''트랜스포머 네트워크'''\n",
        "    def __init__(self, params):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = Encoder(params)\n",
        "        self.decoder = Decoder(params)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        \" src = [배치 사이즈, 소스 문장 길이] \"\n",
        "        \" tgt = [배치 사이즈, 타겟 문장 길이] \"\n",
        "\n",
        "        enc_out = self.encoder(src)\n",
        "        dec_out, attn = self.decoder(tgt, src, enc_out)\n",
        "        return dec_out, attn\n",
        "\n",
        "    def count_params(self):\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "I802EiNE8NEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScheduledOptim:\n",
        "    '''스케줄 옵티마이저'''\n",
        "    def __init__(self, optimizer, warmup_steps):\n",
        "        self.init_lr = np.power(params['hidden_dim'], -0.5)\n",
        "        self.optimizer = optimizer\n",
        "        self.step_num = 0\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def step(self):\n",
        "        self.step_num += 1\n",
        "        lr = self.init_lr * self.get_scale()\n",
        "\n",
        "        for p in self.optimizer.param_groups:\n",
        "            p['lr'] = lr\n",
        "\n",
        "        self.optimizer.step()\n",
        "\n",
        "    def zero_grad(self):\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "    def get_scale(self):\n",
        "        return np.min([\n",
        "            np.power(self.step_num, -0.5),\n",
        "            self.step_num * np.power(self.warmup_steps, -1.5)\n",
        "        ])"
      ],
      "metadata": {
        "id": "cXBcDsj_8b0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "\n",
        "torch.manual_seed(32)\n",
        "torch.cuda.manual_seed(32)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "7zwPdJ1h_DOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Transformer(params)\n",
        "\n",
        "model.to(device)\n",
        "print(f'The model has {model.count_params():,} trainable parameters')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "criterion.to(device)\n",
        "\n",
        "optimizer = ScheduledOptim(\n",
        "    optim.Adam(model.parameters(), betas = (0.9, 0.98), eps = 1e-9),\n",
        "    warmup_steps = 2000\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djhhDfLD8b9E",
        "outputId": "06e0511d-9bd7-4c76-e83e-e11fd8c20859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 54,378,496 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "start_tic = time.time()\n",
        "\n",
        "for epoch in tqdm(range(params['num_epoch']), desc=\"epoch\"):\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "\n",
        "  tic = time.time()\n",
        "  for src, tgt in tqdm(zip(src_iter, tgt_iter), total = len(src_iter), desc = \"training\", leave = False, mininterval = 10):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    logits, _ = model(src, tgt[:, :-1])\n",
        "\n",
        "    logits = logits.contiguous().view(-1, logits.size(-1))\n",
        "    golds = tgt[:, 1:].contiguous().view(-1)\n",
        "\n",
        "    loss = criterion(logits, golds)\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss = epoch_loss / len(src_iter)\n",
        "  toc = time.time()\n",
        "\n",
        "  print(f'Epochs : {epoch+1:02} | Train Loss : {train_loss:.3f} | Time : {toc - tic}')\n",
        "  tic = time.time()\n",
        "\n",
        "  torch.save(model.state_dict(), f'./epoch_{epoch}.pth')\n",
        "  toc = time.time()\n",
        "  print(f'epoch_{epoch}.pth 저장까지 걸린 시간 = {toc - tic}만큼 걸렸습니다.')\n",
        "\n",
        "end_tic = time.time()\n",
        "print(f'총 걸린 시간 = {end_tic - start_tic}만큼 걸렸습니다.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE-8I1b78cFK",
        "outputId": "efcdba00-3ad0-4c5a-e35a-985afe46f184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:   0%|          | 0/5 [00:00<?, ?it/s]\n",
            "training:   0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\n",
            "training:   0%|          | 2/469 [00:17<1:06:31,  8.55s/it]\u001b[A\n",
            "training:   0%|          | 2/469 [00:29<1:06:31,  8.55s/it]\u001b[A\n",
            "training:   1%|          | 4/469 [00:32<1:03:19,  8.17s/it]\u001b[A\n",
            "training:   1%|▏         | 6/469 [00:48<1:01:52,  8.02s/it]\u001b[A\n",
            "training:   1%|▏         | 6/469 [01:00<1:01:52,  8.02s/it]\u001b[A\n",
            "training:   1%|▏         | 7/469 [01:02<1:12:04,  9.36s/it]\u001b[A\n",
            "training:   2%|▏         | 9/469 [01:18<1:07:25,  8.79s/it]\u001b[A\n",
            "training:   2%|▏         | 9/469 [01:30<1:07:25,  8.79s/it]\u001b[A\n",
            "training:   2%|▏         | 11/469 [01:34<1:05:28,  8.58s/it]\u001b[A\n",
            "training:   2%|▏         | 11/469 [01:50<1:05:28,  8.58s/it]\u001b[A\n",
            "training:   3%|▎         | 13/469 [01:53<1:07:01,  8.82s/it]\u001b[A\n",
            "training:   3%|▎         | 13/469 [02:10<1:07:01,  8.82s/it]\u001b[A\n",
            "training:   3%|▎         | 15/469 [02:23<1:22:46, 10.94s/it]\u001b[A\n",
            "training:   3%|▎         | 16/469 [02:38<1:28:35, 11.73s/it]\u001b[A\n",
            "training:   4%|▎         | 17/469 [02:55<1:37:14, 12.91s/it]\u001b[A\n",
            "training:   4%|▍         | 18/469 [03:17<1:53:03, 15.04s/it]\u001b[A\n",
            "training:   4%|▍         | 19/469 [03:41<2:09:12, 17.23s/it]\u001b[A\n",
            "training:   4%|▍         | 20/469 [04:07<2:25:47, 19.48s/it]\u001b[A\n",
            "training:   4%|▍         | 21/469 [04:32<2:36:55, 21.02s/it]\u001b[A\n",
            "training:   5%|▍         | 22/469 [04:59<2:50:19, 22.86s/it]\u001b[A\n",
            "training:   5%|▍         | 23/469 [05:27<2:59:51, 24.20s/it]\u001b[A\n",
            "training:   5%|▌         | 24/469 [05:55<3:08:19, 25.39s/it]\u001b[A\n",
            "training:   5%|▌         | 25/469 [06:27<3:21:21, 27.21s/it]\u001b[A\n",
            "training:   6%|▌         | 26/469 [06:54<3:20:58, 27.22s/it]\u001b[A\n",
            "training:   6%|▌         | 27/469 [07:20<3:17:39, 26.83s/it]\u001b[A\n",
            "training:   6%|▌         | 28/469 [07:44<3:10:30, 25.92s/it]\u001b[A\n",
            "training:   6%|▌         | 29/469 [08:09<3:08:54, 25.76s/it]\u001b[A\n",
            "training:   6%|▋         | 30/469 [08:35<3:08:00, 25.70s/it]\u001b[A\n",
            "training:   7%|▋         | 31/469 [08:58<3:03:21, 25.12s/it]\u001b[A\n",
            "training:   7%|▋         | 32/469 [09:20<2:55:38, 24.11s/it]\u001b[A\n",
            "training:   7%|▋         | 33/469 [09:46<2:58:08, 24.51s/it]\u001b[A\n",
            "training:   7%|▋         | 34/469 [10:09<2:55:28, 24.20s/it]\u001b[A\n",
            "training:   7%|▋         | 35/469 [10:31<2:50:52, 23.62s/it]\u001b[A\n",
            "training:   8%|▊         | 36/469 [10:55<2:51:06, 23.71s/it]\u001b[A\n",
            "training:   8%|▊         | 37/469 [11:20<2:52:46, 24.00s/it]\u001b[A\n",
            "training:   8%|▊         | 38/469 [11:40<2:44:38, 22.92s/it]\u001b[A\n",
            "training:   8%|▊         | 39/469 [12:04<2:44:52, 23.01s/it]\u001b[A\n",
            "training:   9%|▊         | 40/469 [12:23<2:36:01, 21.82s/it]\u001b[A\n",
            "training:   9%|▊         | 41/469 [12:45<2:37:11, 22.04s/it]\u001b[A\n",
            "training:   9%|▉         | 42/469 [13:05<2:31:32, 21.29s/it]\u001b[A\n",
            "training:   9%|▉         | 43/469 [13:27<2:32:51, 21.53s/it]\u001b[A\n",
            "training:   9%|▉         | 44/469 [13:48<2:32:32, 21.54s/it]\u001b[A\n",
            "training:  10%|▉         | 45/469 [14:10<2:31:46, 21.48s/it]\u001b[A\n",
            "training:  10%|▉         | 46/469 [14:29<2:27:41, 20.95s/it]\u001b[A\n",
            "training:  10%|█         | 47/469 [14:49<2:24:11, 20.50s/it]\u001b[A\n",
            "training:  10%|█         | 48/469 [15:09<2:23:26, 20.44s/it]\u001b[A\n",
            "training:  10%|█         | 49/469 [15:27<2:17:51, 19.70s/it]\u001b[A\n",
            "training:  11%|█         | 50/469 [15:46<2:15:36, 19.42s/it]\u001b[A\n",
            "training:  11%|█         | 51/469 [16:05<2:13:40, 19.19s/it]\u001b[A\n",
            "training:  11%|█         | 52/469 [16:22<2:09:06, 18.58s/it]\u001b[A\n",
            "training:  11%|█▏        | 53/469 [16:40<2:07:57, 18.45s/it]\u001b[A\n",
            "training:  12%|█▏        | 54/469 [16:56<2:02:34, 17.72s/it]\u001b[A\n",
            "training:  12%|█▏        | 55/469 [17:12<1:59:24, 17.31s/it]\u001b[A\n",
            "training:  12%|█▏        | 56/469 [17:31<2:01:30, 17.65s/it]\u001b[A\n",
            "training:  12%|█▏        | 57/469 [17:48<1:59:38, 17.42s/it]\u001b[A\n",
            "training:  12%|█▏        | 58/469 [18:02<1:53:56, 16.63s/it]\u001b[A\n",
            "training:  13%|█▎        | 59/469 [18:18<1:50:29, 16.17s/it]\u001b[A\n",
            "training:  13%|█▎        | 60/469 [18:33<1:48:57, 15.98s/it]\u001b[A\n",
            "training:  13%|█▎        | 61/469 [18:49<1:48:38, 15.98s/it]\u001b[A\n",
            "training:  13%|█▎        | 62/469 [19:05<1:48:20, 15.97s/it]\u001b[A\n",
            "training:  13%|█▎        | 63/469 [19:21<1:48:38, 16.05s/it]\u001b[A\n",
            "training:  14%|█▎        | 64/469 [19:38<1:48:52, 16.13s/it]\u001b[A\n",
            "training:  14%|█▍        | 65/469 [19:54<1:50:05, 16.35s/it]\u001b[A\n",
            "training:  14%|█▍        | 66/469 [20:10<1:48:07, 16.10s/it]\u001b[A\n",
            "training:  14%|█▍        | 67/469 [20:25<1:45:26, 15.74s/it]\u001b[A\n",
            "training:  14%|█▍        | 68/469 [20:39<1:42:57, 15.41s/it]\u001b[A\n",
            "training:  15%|█▍        | 69/469 [20:54<1:40:23, 15.06s/it]\u001b[A\n",
            "training:  15%|█▍        | 70/469 [21:08<1:38:42, 14.84s/it]\u001b[A\n",
            "training:  15%|█▌        | 71/469 [21:22<1:36:08, 14.49s/it]\u001b[A"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'\n",
        "model.to(device)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "sent = \"금융\"\n",
        "proc_sent = kor_tokenizer.encode(sent)\n",
        "post_proc_sent = postprocess(proc_sent.ids)\n",
        "\n",
        "input_tensor = torch.LongTensor(post_proc_sent).to(device)\n",
        "input_tensor = input_tensor.unsqueeze(0)\n",
        "\n",
        "output_tensor = torch.LongTensor([1]).to(device).unsqueeze(0)\n",
        "\n",
        "with torch.no_grad():\n",
        "  for _ in range(10):\n",
        "    logits, _ = model(input_tensor, output_tensor)\n",
        "    next_token = logits.argmax(-1)[:, -1]\n",
        "    output_tensor = torch.cat([output_tensor, next_token.unsqueeze(-1)], dim = -1)\n",
        "\n",
        "    if next_token.item() == 2:\n",
        "      break\n",
        "\n",
        "decoded_output = eng_tokenizer.decode(output_tensor.squeeze().tolist())\n",
        "print(decoded_output)\n",
        "\n",
        "with torch.no_grad():\n",
        "  for _ in range(10):\n",
        "    logits, _ = model(input_tensor, output_tensor)\n",
        "    print(\"Logits : \", logits)\n",
        "    print(\"Argmax : \", logits.argmax(-1))\n",
        "\n",
        "    next_token = logits.argmax(-1)[:, -1]\n",
        "    output_tensor = torch.cat([output_tensor, next_token.unsqueeze(0)], dim = -1)\n",
        "\n",
        "    print(\"Output_Tensor : \", output_tensor)\n",
        "\n",
        "    if next_token.item() == 2:\n",
        "      break\n",
        "\n",
        "print(\"Decoding Output Tensor : \", output_tensor.squeeze().tolist())\n",
        "decoded_output = eng_tokenizer.decode(output_tensor.squeeze().tolist())\n",
        "print(decoded_output)"
      ],
      "metadata": {
        "id": "x4B72Htg8cTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = 'cpu'\n",
        "model.to(device)\n",
        "\n",
        "model.eval()\n",
        "sent = \"입력 값\"\n",
        "\n",
        "proc_sent = kor_tokenizer.encode(sent)\n",
        "post_proc_sent = postprocess(proc_sent.ids)\n",
        "\n",
        "input_tensor = torch.LongTensor(post_proc_sent).to(device)\n",
        "input_tensor = input_tensor.unsqueeze(0)  # 배치 차원 추가\n",
        "\n",
        "output_tensor = torch.LongTensor([1]).to(device).unsqueeze(0)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for _ in range(10):\n",
        "        logits, _ = model(input_tensor, output_tensor)\n",
        "        next_token = logits.argmax(-1)[:, -1]\n",
        "        output_tensor = torch.cat([output_tensor, next_token.unsqueeze(-1)], dim=-1)\n",
        "\n",
        "        if next_token.item() == 2:\n",
        "            break\n",
        "\n",
        "# 번역된 토큰들을 디코딩\n",
        "decoded_output = eng_tokenizer.decode(output_tensor.squeeze().tolist())\n",
        "print(\"번역 결과:\", decoded_output)\n"
      ],
      "metadata": {
        "id": "hR572k3zoGGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력 토큰이 어떤 의미인지 확인합니다\n",
        "print(\"Token ID  corresponds to:\", eng_tokenizer.decode([2474]))\n"
      ],
      "metadata": {
        "id": "64Qt5Ib-Ipuz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}